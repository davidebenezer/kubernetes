Q&A Chapter 2
===============

1. Which Flag can you use with kubeadm to supply a custom configuration file?  --config
2. what does 8 in k8s specify? 8 letters between k and s in kubernetes
3. which kubernetes component manages containers on an individual node? kubelet
4. what is the primary feature of kubernetes? Container Orchestration
5. what is a namespace? A mechanism for isolating groups of resources within a single cluster.
6. Which flag allows you to specify which Namespace you want to interact with when using kubectl? -n or --namespace
7. What is Kubernetes control pane? A collection of components that manage the cluster globally
8. What does kubeadm do? Simplifies the process of building kubernetes clusters


Notes:
======

Kompas  - Helps in migrating docker compose to kubernetes objects
Helm - Use chart to maintain kubernetes templates to easily create complex architecture
Kustomize - Used for maintaining kubernetes templates similar to Helm

High Availability -- We need to have more than one Controle Plane(e.g Node1, Node2) In that case we need to 
	* communicate to kube-api-server through load balancer
	* Kubelet uses the load balancer to communicate with kube api server
	
Design patters for etcd in multi control plance set up
Design Pattern 1:
	stacked etcd - (kube-api as well run on each control pane node)etcd run in same node as control pane. 
					each control plane will have its own etcd instance
Design Pattern 2:
	external etcd - etcd will run outside of control pane nodes. Multiple etcd will be running.
	
What is draining?
	when performing maintenancy, you may sometimes need to remove a kubernetes node from sevice
	To do this, you can drain the node. Containers running on the node will be gracefully terminated (and potentially rescheduled on another node).
	
	Ignoring Daemon Sets:
		When draining a node, you may need to ignore DaemonSets(pods that are tied to each node). If you have DaemontSet pods running on the
			node, you will likely need to use the --ignore-daemonsets flag.
			
	$ kubectl drain <node name> --ignore daemonsets
	
	(drain might error out if we dont ignore daemonsets)
	
Uncordoning a Node1
	If the node remains part of the cluster, you can allow pods to run on the node again when maintenance is complete using 
		kubectl uncordon command.
	
	$ kubectl uncordon <node name>
	
etcd
****

Why backup etcd?
	etcd is the backend data storage solution for your kubernetes cluster. As such, all your kubernetes objects, application, and configurations
		are stored in etcd.
		Therefore, you will likely want to be able to back up your cluster's data by backing up etcd.
		You can backup etcd using etcd command line tool etcdctl.
		
		
		Backup etcd
		***********
		$ ETCDCTL_API=3 etcdctl --endpoints $ENDPOINT snapshot save <file name>
		
		Restore etcd
		************
		$ ETCDCTL_API=3 etcdctl snapshot restore <file name>
		
		Restore creates a temporary logical cluster in order to re populate the data from saved backup file.
		
Q&A Chapter 2
=============

1. which tool provides a command-line interface for kubernetes? kubectl
2. which software does kubernetes use to store data about the stare of the cluster? Etcd
3. Which tool(s) allow you to create Kubernete clusters? MiniKube, Kubeadm (Helm allows you to template k8s object, it does not help build clusters)
4. Which command is used to safely evict your pods from a node before maintenance on the node? kubectl drain
5. What command can you use to allow Pods to be scheduled on a previously-drained node after Node maintenance is complete? kubectl uncordon
6. Which tool can help you perform a Kubernetes upgrade? kubeadm
7. which of the following options are for a highly-available Etcd architecture? External Etcd, Stacked Etcd
8. Which command allows you to upgrade control plane components? Kubectl upgrade apply
9. Which command-line tool allows you to interact with Etcd and perform backups? etcdctl
10. How can you make Kubernetes highly available? Have multiple control plane nodes

Notes:
======

what id kubectl? 
	kubectl is a command line tool that allows you to interact with kubernetes. kubectl uses the Kubernetes API to communicate with the cluster
		and carry out your commands.
		" You can use kubectl to deploy applications, inspect and manage cluster resources, and view logs".
		
kubectl get
***********
	Use kubectl get to list objects in the Kuubernetes cluster.
	
	$ kubectl get <object type> <object name> -o <output> --sort-by <JSONPath> --selector <selector>
	
kubectl describe
****************
	You can get detailed information about Kubernetes objects using kubect describe
	
	$ kubectl describe <object type> <object name>

kubectl create
**************
	Use kubectl create to create objects
	
	Supply a YAML file with -f to create an object from a YAML descriptor stored in the file.
	
	If you attempt to create an object that already exists, an error will occur.
	
	$ kubectl create -f <file name>
	
kubectl apply
*************
	kubectl apply is similar to kubectl create. However, if you use kubectl apply on an object that already exists, it will modify the
		existing object, if possible.
		
	$ kubectl apply -f <file name>
	
Kubectl delete
**************
	kubectl delete <object type> <object name>
	
kubectl exec
************
	kubectl exec can be used to run commands inside containers. Keep in mind, in order for a command to succeed, the necessary software
		must exist within the container to run it.
	For pods with  multiple containers, specify the container name with -c. Not needed for pod with only one container
		
	$ kubectl exec <pod name> -c <container  name> -- <command>
	
kubectl get (provides additional info)

kubectl api-resources (gives complete list of resources)

RBAC in K8s
===========

	Role-based access control(RBAC) in K8s allows you to control what users are allowed to do and access within your cluster.
	For ex, you can use RBAC to allow developers to read metadata and logs from Kubernetes pods but not make changes to them.
	
RBAC Objects
============
	Role & Cluster role
	*******************
	
	Roles and ClusterRoles are Kubernetes objects that define a set of permissions. These permissions determine what users can do in the cluster.
	A Role defines permissions within a particular namespace, and a ClusterRole defines cluster-wide permissions not specific to a single 
		namespace
	
	Role Binding and Cluster Role Binding
	*************************************
	
	Role Binding and ClusterRoleBinding are objects that connect Roles and Cluster Roles to users.
	Role Ref connects Role Binding to the actual Role
	
	
What is a Service Account?
	
	In k8s, as service account is an account used by container processes within Pods to authenticate with the K8s API
	If your pods need to communicate with the K8s API, you can use service accounts to control their access
	
		apiversion: v1
		kind: ServiceAccount
		metadata:
			name: my-serviceaccount
			
	You can managge access control for service accounts, just like any other user, using RBAC objects.
	
	Bind service accounts with ClusterRoles or ClusterRoleBindings to provide access to K8s API functionality.
	

Kubernetes Metrics Server
=========================

	In order to view metrics about the resources pods and containers are using, we need an add-on to collect nd provide that data.
		One such add-on is Kubernetes Metrics Server.
		
	Kubectl top
	***********
		with kubectl top, you can view data about resource usage in your pods and nodes. kubectl top also supports flags like
			--sort-by and --selector.
			
		$ kubectl top pod --sort-by <JSONPath> -- selector <selector>

Q&A
***

1. How can you assign permissions to ServiceAccounts? RBAC
2. Which flag allows you to save the command that was used to make a change? --record
3. When using kubectl get, which flag allows you to filter results by label? --selector
4. Which Kubernetes object defines a set of permissions and exists outside of any Namespace? ClusterRole
5. Which tool collects data about resource usage by each container/Pod? Metrics Server
6. Which command can be used to display resource usage data for Pods? kubectl top
7. Which Kubernetes Object can apply a Role to a user or ServiceAccount, but only within a particular Namespace? RoleBinding
8. Which flag allows you to see what would happen when creating an object without actually creating the object? --dry-run=client
9. Which object allows you to create an account used by Pods to access the Kubernetes API? ServiceAccount
10. Which command shows detailed information about a Kubernetes object in a human-readable format? kubectl describe


Managing Application Configuration
**********************************
	When you are running applications in Kubernetes, you may want to pass dynamic values to your applications at runtime to control
		how they behave. This is known as application configuration.
		
	ConfigMaps
	**********
		You can store configuration data in Kubernetes using ConfigMaps. ConfigMaps store data in the form of a key-value map.
			ConfigMap data can be passed to your container applications.
			
		apiVersion: v1
		kind: ConfigMap
		metadata:
			name: my-configmap
		data:
			key1: value1
			key2: value2
			key3:
				subkey:
					morekeys: data
					evenmore: some more data
			key4:
				you can also do multi-line data.
				
	Secrets:
	********
		Secrets are similar to ConfigMaps but are designed to store sensitive data, such as passwords or API keys, more securely. They are 
			created and used similarly to ConfigMaps. Secret values should be base64 encoded
			
		apiVersion: v1
		kind: Secret
		metadata:
			name: my-secret
		type: Opaque
		data:
			username: user
			password: mypass
		
	Environment Variables
	*********************
		You can pass ConfigMap and Secret data to your containers as environment variables. These variables will be visible to container process
			at runtime.
			
			pod specification
			*****************
			spec:
				containers:
				- ...
					env:
					-name : ENVVAR
					 valueFrom:
						configMapKeyRef:
							name: my-configmap
							key: mykey
	
	Configuration Volumes
	*********************
		Configuration data from ConfigMaps and Secrets can also be passed to containers in the form of mounted volumes. This will cause the
			configuration data to appear in files available to the container file system.
		Eah top-level key in the configuration data will appear as a file containing all keys below that top-level key.
		
			...
			volumes:
			- name: secret-vol
			  secret:
			    secretName: my-secret
	
	

Managing Container Resources
============================

	Resource Requests
	*****************
		Resource requests allow you to define amount of resources(such as CPU or memory) you expect a container to use. The Kubernetes
			scheduler will use resource requests to avoid scheduling pods on nodes that do not have enough available resources.
			
			Tip: Containers are allowed to use more(or less) than the requested resources. Resource request only affect the scheduling.
			It does not force the container to remain within the limits
			
		Memory is measured in bytes. CPU is measured in CPU units, which are 1/1000 of one CPU.
		
			apiVersion: v1
			kind: Pod
			metadata:
				name: my-pod
			spec:
				containers:
				- name: busybox
				  image: busybox
				  resources:
				    requests:
					  cpu: "250m"
					  memory: "128Mi"
					  
	Resource Limits
	***************
		Resource limits provide a way for you to limit the amount of resources your containers can use. The container runtime is
			responsible for enforcing these limits, and different container runtimes do this differently.
			
			Tip: Some runtimes will enforce these limits by terminating container processes that attempt to use more than
				the allowed amount of resources.
				
				apiVersion: v1
				kind: Pod
				metadata:
					name:  my-pod
				spec:
					containers:
					- name: busybox
					  image: busybox
					  resources:
					    limits:
						  cpu: "250m"
						  memory: "128Mi"
						  
Monitoring Container Health With Probes
=======================================
	Container Health
	****************
		K8s provides a number of features that allow you to build robust solutions, such as the ability to automatically restart
			unhealthy containers. To make the most of these features, K8s needs to be able to accurately determine the status 
			of your applications. This means actively monitoring container health.
			
		Liveness Probes
		***************
			Liveness probes allow you to automatically determine whether or not a container application is in a healthy state.
			
			By Default , K8s will only consider a container to be "down" if the container process stops.
			
			Liveness probes allow you to customize this detection mechanism and make it more sophisticated.
			
		Startup Probes
		**************
			Startup probes are very similar to liveness probes. However, while liveness probes run constantly on a schedule,
				start up probes run at container startup and stop running once they succeed. 
			
			They are used to determine when the application has successfully started up. Start up probes are especially useful for 
				legacy applications that can have a long startup times.
				
		Readiness Probes
		****************
			Readiness probes are used to determine when a container is ready to accept requests. When you have a service backed by 
				multiple container endpoints, user traffic will not be sent to a particular readiness checks defined by their
				readiness probes.
			
			Use readiness probes to prevent user traffic from being sent to pods that are still in the process of starting up
      

Building Self Healing Pods
==========================
  Restart Policies
  ****************
    K8s can automatically restart containers when they fail. Restart policies allow you to customize this behaior by defining when you 
      want a pod's containers to be automatically restarted.
      
    Restart policies are an important component of self-healing applications, which are automatically repaired when a problem arises.
    
    There are three possible values for a pod's restart policy in K8s: Always, OnFailure and Never
    
    Always:
    *******
      Always is the default restart policy in K8s. With this policy, containers will always be restarted if they stop, even if they 
        completed successfully. Use this policy for applications that should always be running.
        
    OnFailure:
    **********
      The OnFailure restart policy will restart containers only if the container process exits with an error code or the container is
        determined to be unhealthy by a liveness probe. Use this policy for applications that need to run successfully and then stop.
        
    Never:
    ******
      The Never restart policy will cause the pod's containers to never be restarted, even if the container exits or a liveness probe fails.
        Use this for applications that should run once and never be automatically restarted
  
  
Multi Container Pod
===================
what is a Multi-Container Pod?
  A Kubernetes Pod can have one or more containers. A Pod with more than one container is a multi-container Pod.
  
  In a multi-container Pod, the containers share resources such as network and storage. They can interact with one another, working
    together to provide functionality.
   
  Best Practice: Keep containers in separate Pods unless they need to share resources.
   
  Cross-Container Interaction
  ***************************
    Containers sharing the same Pod can interact with one another using shared resources.
    
    Network:
    ********
      Containers share the same networking namespace and can communicate with one another on any port, even if that port is not 
        exposed to the cluster.
        
    Storage:
    ********
      Containers can use volumes to share data in a Pod.
      
    Example Use Case
    ****************
      You have an application that is hard-coded to write log output to a file on disk.
      
      You add a secondary container to the Pod (sometimes called a sidecar) that reads the log file from a shared volume and print it
        to the console so the log output will appear in the container log.
      

Init Containers
===============
  Init Containers are containers that run once during the startup process of a pod. A pod can have any number of init containers, and they
    will each run once (in order) to completion.
  
  Each init container runs in sequence. Only when the first init container runs, the second will start and actual container will be started 
    once all the init containers are started in order.
  
  You can use init containers to perform a variety of startup tasks. They can contain and use software and setup scripts that are not 
    needed by your main containers.
    
  They are often useful in keeping your main containers lighter and more secure by offloading startup tasks to a separate container.
  
  Use cases for initi containers
  ******************************
    Some sample use cases for init containers:
    
    * Cause a pod to wait for another K8s resource to be created before finishing startup.
    * Perform sensitive startup steps securely outside of app containers
    * Populate data into a shared volume at startup
    * Communicate with another service at startup
  
		
Q&A
***

1. When do init containers run? Run to completion before the main container(s) start
2. which of the following probes run only during the container startup process? Startup probes
3. What kubernetes feature can you use to prevent containers from using more than a set amount of resources? Resource limits
4. What does a resource request do(select all that apply)? Prevents Pods from being scheduled on Nodes without sufficient resources.
                                                           Allows you to define the amount of resources you expect a container to use.
5. what can you use to customize how Kubernetes measure the health of a container? Liveness probe
6. Which of the following are ways containers sharing the same Pod can interact? (choose all that apply) 
      Shared Storage Volumes
      Network ports that are not exposed to cluster
7. You have a container that is designed to run a batch job. It needs to run successfully, but should not be run again once it succeeds.
    which restart policy should you use? OnFailure
8. What can you use to customize what happens when a container stops running? Restart Policy
9. Which of the followig situations could init containers be used for? 
    * Make a Pod wait for another resource to be available before finishing startup.
    * Put data into a shared volume so that the main container(s) can access it.
    * Perform startup steps involving sensitive data outside the main container(s).
10. How  many containers can you have per Pod? Atleast one or more
11. What object should you use to store a password? Secret
12. What object should you use to store non-sensitive configuration data? ConfigMap

Exploring K8s Scheduling
========================
what is scheduling?
  The process of assigning Pods to Nodes so kubelets can run them.

  Scheduler
  *********
    Control plane component that handles scheduling

  Sheduling Process
  *****************
    THe Kubernetes Scheduler selects a suitable Node for each Pod. It takes into acccount things like:
      * Resource requests vs available node resources.
      * Various configurations that affect scheduling using node labels
      
      nodeSelector
      ************
        You can configure a nodeSelector for your Pods to limit which Node(s) the Pod can be scheduled on.
        
        Node selectors use node labels to filter suitable nodes
        
				apiVersion: v1
				kind: Pod
				metadata:
					name:  nginx
				spec:
					containers:
					- name: nginx
					  image: nginx
            nodeSelector:
              mylabel: myvalue
              
       nodeName:
       *********
        You can bypass scheduling and assign a Pod to a specific Node by name using nodeName.
				apiVersion: v1
				kind: Pod
				metadata:
					name:  nginx
				spec:
					containers:
					- name: nginx
					  image: nginx
          nodeName: k8s-worker1
          
Using Daemon Sets
*****************
What is a DaemonSet?
  Automatically runs a copy of a Pod on each node.
  
  DaemonSets will run a copy of the Pod on new nodes as they are added to the cluster.
  
  DaemonSets and Scheduling
  *************************
    DaemonSets respect normal scheduling rules around node labels, taints and tolerations. If a pod would not normally be scheduled 
      on a node, a DaemonSet will not create a copy of the Pod on that Node.
      
      
Using Static Pods
*****************
What is a Static Pod?
  A Pod that is managed directly by the kubelet on a node, not by the K8s API server. They can run even if there is no K8s API server present.
  
  Kubelet automatically creates static Pods from YAML manifest files located in the manifest path on the node.
  
  Mirror Pods
  ***********
    Kubelet will create a mirror Pod for each static Pod. Mirror Pods allow you to see the status of the static Pod via the K8s API,
      but you cannot change or manage them via the API.
      
    Mirror Pod is just a ghost representation of static pod in the API
    
    
Q&A
***

1. How can you create a Pod that will run on a Node even if there is no Kubernetes API Server present? Static Pod
2. What PodSpec attribute can you use to limit which node(s) a Pod will run on based upon Node labels? nodeSelector
3. What is a Mirror Pod? A representation of a static Pod in the Kubernetes API.
4. Which of the following PodSpec attributes is guaranteed to cause a Pod to run on a specific node, regardless of that Node's labels? nodeName
5. You need to run exactly one Pod replica on each worker Node. What would you use to accomplish this? DaemonSet
6. You have a DaemonSet running a replica on each Node. Assuming you have no special taints on your Nodes, 
    what happens when you add a new Node to the cluster?  A new replica is created to run on the new Node.
    
    
Deployments
===========
What is a Deployment?
  A K8s object that defines a desired state for a ReplicaSet(a set of replica Pods). The Deployment Controller seeks to maintain the 
    desired state by creating, deleting and replacing Pods with new configurations.
    
  A Deployment's Desired State Includes...
    * replicas - The number of replica Pods the Deployment will seek to maintain
    * selector - A label selector used to identify the replica Pods managed by the Deployment
    * template - A template Pod definition used to create replica Pods
    
  Use Cases
  *********
    There are many use cases for Deployments, such as:
      * Easily scale an application up or down by changing the number of replicas.
      * Perform rolliing updates to deploy a new software version.
      * Rollback to a previous software version.
      

Scaling Applications with Deploymments
======================================
what is scaling?
  scaling refers to dedicating more(or fewer) resources to an application in order to meet changing needs.
  
  K8s Deployments are very useful in horizontal scaling, which involves changing the number of containers running an application.
  
  Deployment Scaling
  ******************
    The Deployment's replicas setting determines how many replicas are desired in its desired state. If the replicas number is changed,
      replica Pods will be created or deleted to satisfy the new number.
      
  How to Scale a Deployment
  *************************
    You can scale a deployment simply by changing the number of replicas in the YAML descriptor with kubectl apply or kubectl edit
    
    ...
    spec:
      replicas: 5
    ...
    
    Or use the special kubectl scale command.
    
    $ kubectl scale \
    deployment.v1.apps/my-deployment \
    -- replicas=5
    

Rolling Updates and Rollbacks
=============================
What is Rolling Update?
  Rolling updates allow you to make changes to a Deployment's Pods at a controlled rate, gradually replacing old Pods with new Pods. 
    This allows you to update your Pods without incurring downtime.
    
What is Rollback?
  If an update to a deployment causes a problem, you can roll back the deployment to a previous working state.
  
  check rollout status
  $ kubectl rollout status deployment.v1.apps/my-deployment
  
  
Q&A
***
1. What does a Deployment's template do? Provides a specification which will be used to create new Pods.
2. You have performed a rolling update of one of your apps, but there are issues with the new code. 
    How can you return to the previous, working state? Perform a rollback on the Deployment
3. Which command(s) can be used to scale a deployment? (select all that apply)
      * kubectl scale
      * kubectl edit deployment
4. Which term refers to changing the number of replicas in a Deployment? Scaling
5. Which term refers to the process of gradually implementing new changes across a Deployment's replica Pods? Rolling Update
6. What Kubernetes object allows you to specify a desired state for a set of replica Pods? Deployment


Kubernetes Networking
=====================
  Kubernetes Networking Model
  ***************************
    The Kubernetes network model is a set of standards that define how networing between Pods behaves.

    There are a variety of different implementations of this model - including the Calico network plugin, which we have been
      using throughout this course
      
  Network Model Architecture
  **************************
    The Kubernetes network model defines how Pods communicate with each other, regardless of which Node they are running on.
    
    Each Pod has its own unique IP address within the cluster.(even if its across nodes)
    
    Any Pod can reach any other Pod using that Pod's IP address. This creates a virtual network that allows Pods to easily
      communicate with each other, regardless of which node they are on
      
CNI Plugins
===========
CNI Plugins are a type of kubernetes network plugin. These plugins provide network connectivity between Pods according to the 
  standard set by the Kubernetes network model. There are multiple CNI plugins available.
  
  Selecting a Network Plugin
  **************************
    Which network plugin is best for you will depend on your specific situation.
    
    Check the Kubernetes documentation for a list of available plugins. You may need to research some of these plugins for yourself,
      depending on your production use case.
    
    The plugin used in this course is Calico.
    
    Installing Network Plugins
    **************************
      Each plugin has its own unique installation process. Early in this course, we installed the Calico network plugin.
      
      Note: Kubernetes nodes will remain NotReady until a network plugin is installed. You will be unable to run Pods while this is the case.
      
Understanding K8s DNS
=====================
  The K8s virtual network uses a DNS(Domain Name System) to allow Pods to locate other Pods and Services using domain names instead of
    IP addresses.
  
  This DNS runs as a Service within the cluster. You can usually find it in the kube-system namespace.
  
  kubeadm clusters use CoreDNS
  
  Pod Domain Names
  ****************
    All pods in our kubeadm cluster are automatically given a domain name of the following form.
    
    pod-ip-address.namespace-name.pod.cluster.local
    
    A Pod in the default namespace with the IP address 192.168.10.100 would have a domain name like this.
    
    192-168-10-100.default.pod.cluster.local
  
  
Network Policies
================
What is a network policy?
  A K8s NetworkPolicy is an object that allows you to control the flow of network communication to and from Pods.
  
  This allows you to build a more secure cluster network by keeping Pods isolated from traffic they do not need
  
  podSelector
  ***********
    Determines to which Pods in the namespace the NetworkPolicy applies.
    
    The podSelector can select Pods using Pod labels.
    
    Note: By default, Pods are considered non-isolated and completely open to all communication.
          If any NetworkPolicy selects a Pod, the pod is considered isolated and will only be open to traffic allowed by 
            NetworkPolicies.
            
    A NetworkPolicy can apply to Ingress, Egress or both.
    
    Ingress
    *******
      Incoming network traffic coming into the Pod from another source.
      
      fromselector
      ************
        Selects ingress(incoming) traffic that will be allowed.
      
    Egress
    ******
      Outgoing network traffic leaving the Pod for another destination.
      
      toselector
      **********
        Selects egress(outgoing) traffic that will be allowed.
        
        spec:
          ingress:
            - from:
            ...
          egress:
            - to:
            ...
            
    podSelector
    ***********
      Select Pods to allow traffic from/to.
      Below allows incoming traffic to a pod from apps matching label db
      
      spec:
        ingress:
          - from:
            - podSelector:
                matchLabels:
                  app: db

      namespaceSelector
      *****************
        Select namesaces to allow traffic from/to
        Allows namespaces based on labels. Any traffic from pods coming from namespaces matching the label will be allowed
        
        spec:
          ingress:
            - from:
              - namespaceSelector:
                  matchLabels:
                    app: db
                    
      ipBlock
      *******
        Select an IP range to allow traffic from/to
        
        spec:
          ingress:
            - from:
              - ipBlock:
                  cidr: 172.17.0.0/16
                  
      
      Ports
      *****
        port: Specifies one or more ports that will allow traffic.
        
        spec:
          ingress:
            - from:
              ports:
                - protocol: TCP
                  port: 80
                  
            Traffic is only allowed if it  matches both an allowed port and one of the from/to rules.
            

Q&A
***
1. What happens to a cluster when no CNI plugin has been installed? Nodes will remain in the NotReady state.
2. From within a Pod, what do you need to do in order to communicate with a Pod on another Node? 
      You can communicate normally using only the other Pod's IP address.
3. Which of the following types of traffic can a single NetworkPolicy object control? Both Ingress and Egress
4. What allows Pods to locate other Pods and Services using a domain name? DNS
5. Which of the following statements about the Kubernetes Network Model is true? (select all that apply)
    * Each Pod has a unique IP address.
    * There is a single virtual network for the entire cluster.
6. What do CNI plugins do? Implement the Kubernetes Network Model.
7. You need to limit network access to a Pod so that only one other Pod can communicate with it. What Kubernetes object should you use?
    NetworkPolicy
8. Which of the following could be a valid domain name for a Pod? 123-123-1-1.dev.pod.cluster.local


kubernetes Services
===================
What is a service?
  Kubernetes Services provide a way to expose an application running as set of Pods.
  
  They provide an abstract way for clients to access applications without needing to be aware of the application's Pods.
  
  Service Routing
  ***************
    Clients make requests to a Service, which routes traffic to its Pods in a load-balanced fashion.
    
    EndPoints
    *********
      Endpoints are the backend entities to which Services route traffic. For a service that routes traffic to multiple Pods,
        each Pod will have an endpoint associated with the Service.
        
        Tip: One way to determine which Pod(s) a Service is routing traffic to is to look at that service's Endpoints.
        
  Service Types
  *************
    Each Service has a type. The Service type determines how and where the Service will expose your application.
      There are four service types:
        * ClusterIp
        * NodePort
        * LoadBalancer
        * ExternalName(outside the scope of CKA)
        
        ClusterIp
        *********
          Services expose applications inside the cluster network. User them when your clients will be other Pods within the cluster
          
        NodePort:
        *********
          Services expose applications outside the cluster network. Use NodePort when applications or users will be accessing your
            application from outside the cluster.
            
        LoadBalancer:
        *************
          Service also expose applications outside the clustr network, but they use an external cloud load balancer to do so.
            This service type only works with cloud platforms that include load balancing functionality.
            
Discovering Kubernetes Services with DNS
========================================
  Service DNS Names
  *****************
    The Kubernetes DNS(Domain Name System) assigns DNS names to Services, allowing applications within the cluster to easily
      locate them.
      
    A service's fully qualified domain name has the following format:
      
      service-name.namespace-name.svc.cluster-domain.example
      
      The default cluster domain is cluster.local.
      
    A Service's fully qualified domain name can be used to reach the service from within any Namespace in the cluster.
    
      my-service.my-namespace.svc.cluster.local
      
    However, Pods within the same Namespace can also simply user the service name.
    
      my-service
      
    
Managing Access from Outside with K8s Ingress
*********************************************
What is an Ingress?
  An Ingress is a Kubernetes object that manages external access to Services in the cluster.
  
  An Ingress is capable of providing more functionality than a simple NodePort Service, such as SSL termination,
    advanced load balancing, or name-based virtual hosting.
    
  Ingress Controllers
  *******************
    Ingress objects actually do nothing by themselves. In order for Ingresses to do anything, you must install one or more
      Ingress Controllers.
      
    There are a variety of Ingress Controllers available, all of which implement different methods for providing external
      access to your Services.
      
      Routing to a Service
      ********************
        Ingresses define a set of routing rules. A routing rule's properties determine to which requests it applies.
        
        Each rule has a set of paths, each with a backend. Requests matching a path will be routed to its associated backend.
        
        In this example, a request to http://<some-endpoint>somepath would be routed to port 80 on the my-service Service.
        
         apiVersion: networing:k8s.io/v1
         kind: Ingress
         metadata:
          name: my-ingress
         spec:
           rules:
           - http:
               paths:
               - path: /somepath
                 pathType: Prefix
                 backend:
                   service:
                     name: my-service
                     port:
                       number: 80
        
      Routing to a Service with Named Port
      ************************************
        If a Service uses a named port, an Ingress can also use the port's name to choose to which port it will route.
        
        apiVersion: v1
        kind: Service
        metadata:
          name: my-service
        spec:
          selector:
            app: MyApp
          ports:
            - name: web
              protocol: TCP
              port: 80
              targetPort: 8080
              
              
         ---
         
         apiVersion: networing:k8s.io/v1
         kind: Ingress
         metadata:
          name: my-ingress
         spec:
           rules:
           - http:
               paths:
               - path: /somepath
                 pathType: Prefix
                 backend:
                   service:
                     name: my-service
                     port:
                       number: web
        
Q&A
***

1. Which Service type exposes a Service externally by listening on a port on each cluster Node? NodePort
2. Which of the following statements accurately describes the Ingress Kubernetes object?
      An object that exposes external access to Services.
3. Which of the following statements about Service DNS are true?
    * Every Service has a domain name.
    * Pods can use domain names to locate Services.
4. What is the term for the entity that an Ingress routes incoming traffic to? backend
5. You have a set of Pods running in the cluster. 
   Which Service type would be the best choice to allow those Pods to be accessed by other Pods within the cluster?
        ClusterIP
6. You have a Service called my-service in the default Namespace. The cluster domain is cluster.local. 
   You are trying to access this Service from a Pod that is also in the default Namespace. 
   Which of the following domain names can you use? (select all that apply)
      * my-service.default.svc.cluster.local
      * my-service
7. What is an endpoint? A backend entity that a Service routes traffic to.
8. You have multiple replica Pods. 
    Which Kubernetes object can allow clients to communicate with these Pods in an abstract way?
        Service


K8s Storage
***********
  Container File System
  *********************
    The container file system is ephemeral. Files on the container's file system exist only as long as the container
      exists.
    If a container is deleted or re-created in K8s, data store on the container file system is lost.
    
  Volumes
  *******
    Many applications need a more persistent method of data storage.
    Volumes allow you to store data outside the container file system while allowing the container to accces the data
      at runtime.
      
  Persistent Volumes
  ******************
    Volumes offer a simple way to provide external storage to containers within the Pod/Container spec.
    Persistent Volumes are a slightly more advanced form of Volume. They allow you to treat storage as an abstract
      resource and consume it using your Pods.
      Container -> Persistent Volume Claim -> Persistent Volume -> External Storage
      
  Volume Types
  ************
    Both Volumes and Persistent Volumes each have a volume type. The volume type determines how the storage is 
      actually handled.
    Various volume types support storage methods such as
      * NFS
      * Cloud storage mechanisms (AWS, Azure, GCP)
      * ConfigMaps and Secrets
      * A simple diretory on the K8s node
      
Volumes and Volume Mounts
*************************
  Regular Volumes can be set up relatively easily within a Pod/container specification.
  
  volumes: 
  ********
    In the Pod spec, these specify the storage volumes available to the Pod. They specify the volume type and
      other data that determines where and how the data is actually stored.
    
  volumeMounts:
  *************
    In the container spec, these reference the volumes in the Pod spec and provide a mountPath(the location on the
      file system where the container process will access the volume data).
      
    You can use volumeMounts to mount the same volume to multiple containers within the same Pod.
    
    This is a powerful way to have multiple containers interact with one another. For example, you could create a 
      secondary sidecar container that processes or transforms output from another container.
  
         apiVersion: v1
         kind: Pod
         metadata:
          name: volume-pod
         spec:
           containers:
           - name: busybox
             image: busybox
             volumeMounts:
             -name: my-volume
              mountPath: /output
                 pathType: Prefix
             volumes:
             - name: my-volume
               hostPath:
                 path: /data
  
  Common Volume Types
  *******************
    There are many volume types, but there are two you may want to be especially aware of.
    
    hostPath: 
    *********
      Stores data in a specified directory on the K8s node.
      
    emptyDir:
    *********
      Stores data in a dynamically created location on the node. This directory exists only as long as the Pod exists
        on the node. The directory and that data are deleted when the Pod is removed. This volume type is very 
        useful for simply sharing data between containers in the same Pod.
    

Kubernetes Persistent Volumes
*****************************
  PersistentVolumes are K8s objects that allow you to treat storage as an abstract resource to be consumed by 
    Pods, much like K8s treats compute resources such as memory and CPU.
  
  A PersistentVolume uses a set of attributes to describe the underlying storage resource (such as disk or cloud
    storage location) whichh will be used to store data.
    
         apiVersion: v1
         kind: PersistentVolume
         metadata:
          name: my-pv
         spec:
           storageClassName: localdisk
           capacity:
             storage: 1Gi
             volumeMounts:
           acccessModes:
             - ReadWriteOnce
                 pathType: Prefix
           hostPath:
             path: /var/output

  Storage Classes
  ***************
    Storage Classes allow K8s administrators to specify the types of storage services they offer on the platform.
    
         apiVersion: v1
         kind: StorageClass
         metadata:
           name: localdisk
         prvisioner: kubernetes.io/no-provisioner
         
    For example, an administrator could create a StorageClass called slow to describe low-performance but 
      inexpensive storage resources, and another called fast for high-performance but more costly resources.
      
      This would allow users to choose storage resources that fit the needs of their applications.
      
         apiVersion: v1
         kind: StorageClass
         metadata:
           name: slow
         prvisioner: kubernetes.io/no-provisioner
         
         apiVersion: v1
         kind: StorageClass
         metadata:
           name: fast
         prvisioner: kubernetes.io/no-provisioner
    
  allowVolumeExpansion
  ********************
  
    The allowVolumeExpansion property of a StorageClass determines whether or not the StorageClass supports the 
      ability to resize volumes after they are created.
      
         apiVersion: v1
         kind: StorageClass
         metadata:
           name: localdisk
         prvisioner: kubernetes.io/no-provisioner
         allowVolumeExpansion: true
         
  reclaimPolicies
  ***************
    A PersistentVolume's persistentVolumeReclaimPolicy determines how the storage resources can be reused when the 
      PersistentVolume's associated PersistentVolumeClaims are deleted.
      
      * Retain: Keeps all data. This requires an administrator to manually clean up the data and prepare the storage
          resource for reuse.
          
      * Delete: Deletes the underlying storage resource automatically (only works for cloud storage resources).
      
      * Recycle: Automatically deletes all data in the underlying storage resource, allowing the PersistentVolume to be
        reused.

         apiVersion: v1
         kind: StorageClass
         metadata:
           name: localdisk
         prvisioner: kubernetes.io/no-provisioner
         persistentVolumeReclaimPolicy: Recycle
         allowVolumeExpansion: true
        
PersistentVolumeClaims
**********************
    A PersistentVolumeClaim represents a user's request for storage resources. It defines a set of attributes similar to
      those of a PersistentVolume(StorageClass, etc)
      
    When a PersistentVolumeClaim is created, it will look for a PersistentVolumme that is able to meet the requested
      criteria. If it finds one, it will automatically be bound to the PersistentVolume.
      
         apiVersion: v1
         kind: PersistentVolumeClaim
         metadata:
           name: my-pvc
         spec:
          storageClassName: localdisk
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: 100Mi

      Using a PersistentVolumeClaim in a Pod
      **************************************
      
      PersistentVolumeClaims can be mounted to a Pod's containers just like any other volume.
      
      If the PersistentVolumeClaim is bound to a PersistentVolume, the containers will use the underlying
        PersistentVolume storage.
        
         apiVersion: v1
         kind: Pod
         metadata:
          name: pv-pod
         spec:
           containers:
           - name: busybox
             image: busybox
             volumeMounts:
             -name: pv-storage
              mountPath: /output
             volumes:
             - name: pv-storage
               persistentVolumeClaim:
                 claimName: my-pvc
      
      Resizing a PersistentVolumeClaim
      ********************************
        You can expand PersistentVolumeClaims without interrupting applications that are using them.
        
        Simply edit the spec.resources.requests.storage attribute of an existing PersistentVolumeClaim, increasing
          its value.
          
        However, the StorageClass must support resizing volumes and must have allowVolumeExpansion set to true.
        
         apiVersion: v1
         kind: PersistentVolumeClaim
         metadata:
          name: my-pvc
         spec:
           storageClassName: localdisk
           accessModes:
             - ReadWriteOnce
         resources:
          requests:
            storage: 200Mi
            

Q&A
****
1. What happens to data on a container file system when the container is deleted? It is lost
2. Which object would be used to abstractly define a storage resource that can be used by users as they are creating Pods?
    PersistentVolume
3. Which of the following statements about PersistentVolumeClaims is true? (select all that apply)
    * PersistentVolumeClaims can sometimes be resized.
    * PersistentVolumeClaims reference a StorageClass.
    * PersistentVolumeClaims can be added to Pods as a volume.
4. Which of the following statements about volumes is true? (select all that apply)
    * volumes are listed in the PodSpec, not the ContainerSpec.
    * You can choose the path within the container where the volume will be mounted.
5. You have two containers in a Pod, and you want them to interact by sharing data using a volume. 
    Assuming you do not need the data to persist if the Pod is deleted, which volume type should you use?
      emptyDir
6. What does a volume type determine? The underlying storage mechanism.
7. What object is used by a Kubernetes administrator to define the types of PersistentVolume storage resources 
    that are available in the cluster? StorageClass
8. There is a PersistentVolume in the cluster, and its PersistentVolumeClaim is deleted, since the user no longer 
    needs to use the PersistentVolume. Which of the following must be true in order for the PersistentVolume to be 
    automatically re-usable? The PersistentVolume must have persistentVolumeReclaimPolicy set to Recycle.


Troubleshooting k8s cluster
***************************
  
  Kube API Server
  ***************
  If the K8s API server is down, you will not be able to use kubectl to interact with the cluster. You may get
    a message that looks something like:
    
    $ kubectl get nodes
    The connection to the server localhost:443 was refused - did you specify the right host or port?
    
    Assuming your kubeconfig is set up correctly, this may mean the API server is down.
    
    Possible fixes:
      Make sure the docker and kubelet services are up and running on your control plane node(s)
      
    Assuming kubectl is healthy and we are able to interact with Kubectl. Next step is checking node status
    
    Checking Node Status
    ********************
      Check the status of your nodes to see if any of them are experiencing issues.
      $ kubectl get nodes
      $ kubectl describe node node_name
      
    If a node is having problems, it may be because of a service is down on that node.
    
    Each node runs the kubelet and container runtime (i.e Docker) services
    
      # check status view the status of service
      $ systemctl status kubelet 
      
      # systemctl start Start a stopped service
      $ systemctl start kubelet
      
      # systemctl enable. Enable a service so it starts automatically on system start up.
      $ systemctl enable kubelet

    Checking System Pods
    ********************
      In a kubeadm cluster, several K8s component run as pods in the kube-system namespace.
      
      Check the status of these components with kubectl get pods and kubectl describe pod.
      
      $ kubectl get pods -n kube-system
      $ kubectl describe pod podname -n kube-system
      
Checking Cluster and Node Logs
******************************

  You can check the logs for K8s-related services on each node using journalctl.
  
    $ sudo journalctl -u kubelet
    $ sudo journalctl -u docker
    
  Cluster Component Logs
  **********************
  
    The Kubernetes cluster components have log output redirected to /var/log. For example.
    
    /var/log/kube-apiserver.log
    /var/log/kube-scheduler.log
    /var/log/kube-controller-manager.log
    
    Note that these log files may not appear for kubeadm clusters, since some components run inside containers.
      In that case, you can access them with kubectl logs.

Troubleshooting Applications
****************************
  Checking pod status
  *******************
  
    $ kubectl get pods
    $ kubectl describe pod pod_name
    $ kubectl exec podname --command
    $ kubectl exec podname -c containername -- command
    
    Note that you cannot use kubectl exec to run any software that is not present within the container
    
    checking container logs
    ***********************
      K8s containers maintain logs, which you can use to gain insight into what is going on within the container.
      
      A container's log contains everything written to the standard output(stdout) and error(stderr) streams
        by the container process.
    
      Kubectl logs
      ************
      
        use the kubectl logs command to view a containers logs.
        $ kubectl logs podname -c containername

Troubleshooting Kubernetes Networking Issues
********************************************
  kube-proxy and DNS
  ******************
    In addition to checking on your K8s networking plugin, it may be a good idea to look at kube-proxy and the 
      K8s DNS if you are experiencing issues within the K8s cluster network.
      
    In a kubeadm cluster, the K8s DNS and kube-proxy run as Pods in the kube-system namespace.
    
  netshoot
  ********
    Tip: You can run a container in the cluster that you can use to run commands to test and gather information
      about network functionality.
    The nicolaka/netshoot image is a great tool for this. This image contains a variety of networking exploration
      and troubleshooting tools.
    Create a container running this image, and then use kubectl exec to explore away!
    

Q&A
****************

1. Which of the following statements is true about container logs in Kubernetes? (select all that apply)
    * When retrieving logs, you must specify the container name if the Pod has multiple containers.
    * You can access container logs using kubectl.
    
2. How can you explore the Kubernetes network from inside that network?
    Create a Pod and run commands inside that Pod.
    
3. In a cluster built with kubeadm, how can you check the status of cluster components such as kube-apiserver?
    Check the status of Pods in the kube-system Namespace.
    
4. Which command allows you to get detailed information about a Pod's status in a human-readable format?
    kubectl describe pod
    
5. You have a Pod called my-pod in the dev Namespace with multiple containers. There is one container called busybox 
    within the Pod. How can you execute the ls command inside that container?
      kubectl exec -n dev my-pod -c busybox -- ls
      
6. What command can you use to view a container's logs?
    kubectl logs
    
7. In a cluster built with kubeadm, how can you find logs for the Kubernetes API Server?
    kubectl logs -n kube-system <api-server-pod-name>
    
8. In a cluster built with kubeadm, which of the following commands would let you view the logs for kubelet?
    sudo journalctl -u kubelet
    
9. Your kubeadm cluster is having issues resolving Service DNS names. 
    Where would you look to make sure the cluster DNS is up and running?
      Look for DNS Pods in the kube-system Namespace.
      
10. What command can you use to view the status of all Nodes in the cluster?
      kubectl get nodes